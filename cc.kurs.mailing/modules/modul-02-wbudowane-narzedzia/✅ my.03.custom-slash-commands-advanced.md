# Custom Slash Commands - Advanced Workflow

> **ğŸ“‹ Uwaga terminologiczna:** Od Claude Code v2.1.3 terminy "custom slash commands" i "skills" sÄ… rÃ³wnowaÅ¼ne. Ta lekcja uÅ¼ywa terminu "komenda", ale wszystko dotyczy rÃ³wnieÅ¼ "skills". Pliki w `.claude/commands/*.md` dziaÅ‚ajÄ… identycznie jak skills. Natomiast, skile, sÄ… bardziej rozbudowane od slash commands i na ich temat porozmawiamy w kolejnych lekcjach.

## Od prostego skryptu do produkcyjnego narzÄ™dzia

Sara, project manager w Å›rednim teamie developerskim, miaÅ‚a problem.

KaÅ¼dy piÄ…tek o 15:00 robiÅ‚a to samo:
1. ZbieraÅ‚a dane z rÃ³Å¼nych plikÃ³w CSV (zadania, PR-y, metryki)
2. KopiowaÅ‚a do Excela
3. SpÄ™dzaÅ‚a godzinÄ™ Å‚Ä…czÄ…c dane, segregujÄ…c, tworzÄ…c podsumowanie
4. WysyÅ‚aÅ‚a raport do zarzÄ…du

45 minut kaÅ¼dego piÄ…tku. Nie liczÄ…c frustracji, gdy jakiÅ› plik miaÅ‚ inny format.

Po lekcji 11 Sara stworzyÅ‚a komendÄ™ `/morning-check` dla porannych raportÃ³w. DziaÅ‚aÅ‚a Å›wietnie. ZainspirowaÅ‚a jÄ… to do stworzenia drugiej komendy: `/weekly-report` dla piÄ…tkowych raportÃ³w do zarzÄ…du. Claude czytaÅ‚ CSV, liczyÅ‚ podstawowe statystyki, generowaÅ‚ raport. 10 minut zamiast 45.

To byÅ‚ Å›wietny start. Ale to dopiero poczÄ…tek historii.

---

## CzÄ™Å›Ä‡ 1: Wszystko dziaÅ‚a... aÅ¼ przestaje

Trzy tygodnie pÃ³Åºniej Sara uÅ¼ywaÅ‚a `/weekly-report` automatycznie. WpisaÅ‚a komendÄ™, wypiÅ‚a kawÄ™, raport gotowy.

PiÄ…tek, 14:50. Sara wpisuje:

```
/weekly-report sprint-data.csv
```

Claude odpowiada komunikatem bÅ‚Ä™du:

```
Error: [Errno 2] No such file or directory: 'sprint-data.csv'

Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
FileNotFoundError: [Errno 2] No such file or directory: 'sprint-data.csv'
```

(Ten komunikat oznacza, Å¼e plik nie zostaÅ‚ znaleziony - "Errno 2" to kod bÅ‚Ä™du systemu, "Traceback" to Å›lad wykonania pokazujÄ…cy gdzie nastÄ…piÅ‚ problem, a "FileNotFoundError" to nazwa bÅ‚Ä™du)

Problem: Plik nazywaÅ‚ siÄ™ `sprint_data.csv` (podkreÅ›lnik zamiast myÅ›lnika). Prosta literÃ³wka. Ale komenda po prostu... przestaÅ‚a dziaÅ‚aÄ‡.

Sara musiaÅ‚a:
1. ZgadnÄ…Ä‡ co poszÅ‚o Åºle (5 min)
2. ZnaleÅºÄ‡ wÅ‚aÅ›ciwÄ… nazwÄ™ pliku (3 min)
3. UruchomiÄ‡ ponownie

Stracone 8 minut + frustracja.

A tydzieÅ„ pÃ³Åºniej - gorzej. Kolega z zespoÅ‚u zapisaÅ‚ plik w niewÅ‚aÅ›ciwym katalogu. Claude wywala bÅ‚Ä…d. Znowu trzeba szukaÄ‡ przyczyny problemu.

### Optymalizacja przez nagÅ‚Ã³wki

Zanim Sara zacznie dodawaÄ‡ error handling, chce ograniczyÄ‡ koszty - plik moÅ¼e byÄ‡ duÅ¼y, a bÅ‚Ä™dy mogÄ… zuÅ¼yÄ‡ duÅ¼o tokenÃ³w.

Sara dodaje nagÅ‚Ã³wki (pamiÄ™tasz z lekcji 11?):

```markdown
---
model: haiku
allowed-tools:
  - Read
  - Bash(ls *)    # Pozwala na komendÄ™ "ls" z dowolnymi argumentami (* = wszystko)
---
```

**Dlaczego?** `model: haiku` uÅ¼ywa prostszego modelu - podstawowa analiza nie wymaga Opus (10x taÅ„sze), a `allowed-tools` daje uprawnienia bez pytania uÅ¼ytkownika (oszczÄ™dza czas).

**WyjaÅ›nienie skÅ‚adni:** `Bash(ls *)` oznacza "zezwÃ³l na uÅ¼ycie komendy bash `ls` z dowolnymi parametrami". Gwiazdka (`*`) to znak specjalny (wildcard), ktÃ³ry oznacza "wszystko" lub "dowolny".

SzczegÃ³Å‚y wszystkich opcji nagÅ‚Ã³wkÃ³w znajdziesz w lekcji 11.

### RozwiÄ…zanie: ObsÅ‚uga bÅ‚Ä™dÃ³w (Error Handling)

Sara otworzyÅ‚a `.claude/commands/weekly-report.md` i przepisaÅ‚a komendÄ™:

Przed:
```markdown
Generate weekly report from CSV: $ARGUMENTS

Steps:
1. Read $ARGUMENTS
2. Calculate metrics
3. Generate summary
4. Save as weekly-report.md
```

Po:
```markdown
Generate weekly report from CSV: $ARGUMENTS

## Step 1: Validation
1. Check if $ARGUMENTS is provided
   - If empty: "Error: Please provide CSV filename"
   - STOP execution

2. Try to Read $ARGUMENTS
   - If file not found:
     * Show: "Error: File not found: $ARGUMENTS"
     * Suggest: Search for similar filenames using Glob pattern: *.csv
     * List all CSV files in current directory
     * STOP execution
   - If file found: Continue

## Step 2: Data Processing
Try:
  - Read CSV
  - Calculate metrics (tasks completed, velocity, etc.)
Catch error:
  - Show: "Error reading CSV: [error message]"
  - Explain: "Check if file is valid CSV format"
  - STOP execution

## Step 3: Generate Report
- Create summary markdown
- Save as weekly-report-[date].md
- Show: "Report saved: weekly-report-2026-02-02.md"
```

1. Walidacja (sprawdzanie poprawnoÅ›ci) argumentÃ³w:
```markdown
If empty: STOP + clear message
```

2. Sprawdzanie bÅ‚Ä™dÃ³w (try-catch) dla kaÅ¼dej operacji:
```markdown
Try: Read file
Catch: Explain what broke + suggest fix
```

3. Pomocne komunikaty bÅ‚Ä™dÃ³w:
```markdown
"Error: File not found"
vs
"Error: File not found: sprint-data.csv
Did you mean one of these?
- sprint_data.csv
- sprint-metrics.csv"
```

NastÄ™pny piÄ…tek Sara pomyliÅ‚a nazwÄ™ pliku. Claude powiedziaÅ‚:

```
Error: File not found: sprint-data.csv

Found similar files:
- sprint_data.csv
- sprint-metrics.csv
- tasks_data.csv

Which one did you mean?
```

30 sekund zamiast 8 minut szukania problemu. Zero frustracji.

---

## CzÄ™Å›Ä‡ 2: Chaos w zespole - wszyscy uÅ¼ywajÄ… inaczej

Sara podzieliÅ‚a siÄ™ komendÄ… z zespoÅ‚em. DodaÅ‚a do `.claude/commands/` (projekt), wszyscy po `git pull` dostali `/weekly-report`.

Problem pojawiÅ‚ siÄ™ szybko.

Janek (programista):
```
/weekly-report wszystkie-dane.txt
```
Claude prÃ³bowaÅ‚ czytaÄ‡ `.txt` jako CSV. BÅ‚Ä…d.

Marta (testerka):
```
/weekly-report dane.xlsx
```
Format Excel. Claude nie ma odpowiednich narzÄ™dzi do odczytu. BÅ‚Ä…d.

Tomek (projektant):
```
/weekly-report
```
Brak argumentu. BÅ‚Ä…d z niezrozumiaÅ‚ym komunikatem.

KaÅ¼dy uÅ¼ywaÅ‚ komendy po swojemu. Sara spÄ™dzaÅ‚a czas pomagajÄ…c innym zamiast oszczÄ™dzaÄ‡ swÃ³j.

### RozwiÄ…zanie: Walidacja + komunikat pomocy

Sara rozbudowaÅ‚a walidacjÄ™:
```markdown
## Argument Validation

1. Check if $ARGUMENTS provided:
   - If empty:
     * Show help message:

       Usage: /weekly-report <filename.csv>

       Example:
         /weekly-report sprint-data.csv
         /weekly-report tasks/weekly-tasks.csv

       Supported format: CSV only
       Required columns: task_id, status, completed_date

     * STOP execution

2. Check file extension:
   - Extract extension from $ARGUMENTS
   - If NOT .csv:
     * Show: "Error: Only CSV files supported"
     * Show: "Your file: $ARGUMENTS (extension: [extension])"
     * Show: "Convert to CSV first or use /analyze-excel for Excel files"
     * STOP execution

3. Check file exists (previous step)

4. Validate CSV structure:
   - Read first row (headers)
   - Check for required columns: task_id, status, completed_date
   - If missing:
     * Show: "Error: Missing required columns"
     * Show: "Found columns: [list]"
     * Show: "Required columns: task_id, status, completed_date"
     * STOP execution
```

Kaskadowa walidacja (validation cascade): KaÅ¼dy poziom sprawdzania dodaje pewnoÅ›Ä‡, Å¼e wszystko jest w porzÄ…dku. Wczesne wyjÅ›cia (gdy coÅ› nie tak) oszczÄ™dzajÄ… czas.

Tomek (designer) prÃ³buje ponownie:
```
/weekly-report
```

Claude odpowiada:
```
Error: Please provide CSV filename

Usage: /weekly-report <filename.csv>

Example:
  /weekly-report sprint-data.csv
  /weekly-report tasks/weekly-tasks.csv

Supported format: CSV only
Required columns: task_id, status, completed_date
```

Tomek wie dokÅ‚adnie co zrobiÄ‡. Brak pytaÅ„ do Sary.

Janek prÃ³buje z .txt:
```
/weekly-report wszystkie-dane.txt
```

Claude odpowiada:
```
Error: Only CSV files supported
Your file: wszystkie-dane.txt (extension: .txt)

Convert to CSV first or use /analyze-excel for Excel files
```

Jasny komunikat, jasne rozwiÄ…zanie.

Metrics:
- Pytania do Sary: 5-7/tydzieÅ„ â†’ 0-1/tydzieÅ„
- BÅ‚Ä™dy uÅ¼ytkownikÃ³w: spadek o 80%
- Sara oszczÄ™dza: 20 minut/tydzieÅ„ na supportowaniu teamu

---

## Wzorce z przemysÅ‚u: Jak robiÄ… to najlepsi

WiodÄ…ce narzÄ™dzia CLI stosujÄ… sprawdzone wzorce error handling, ktÃ³re Sara moÅ¼e wykorzystaÄ‡ w swoich komendach:

### Git - Inteligentne sugestie

```bash
$ git comit
git: 'comit' is not a git command. See 'git --help'.

Did you mean this?
    commit
```

Git uÅ¼ywa algorytmu **Damerau-Levenshtein** do sugerowania podobnych komend - jeden bÅ‚Ä…d literowy nie zatrzymuje pracy. OdlegÅ‚oÅ›Ä‡ edycyjna miÄ™dzy sÅ‚owami pozwala znaleÅºÄ‡ najbliÅ¼sze dopasowanie.

### NPM - Kontekst + rozwiÄ…zanie

```bash
$ npm install package
npm ERR! code EACCES
npm ERR! Error: EACCES: permission denied, access '/usr/local/lib'

This is usually caused by running npm without administrator privileges.
Fix: Run with sudo or configure npm to use a different directory.
See: https://docs.npmjs.com/resolving-eacces-permissions-errors
```

NPM wyjaÅ›nia w strukturze: **co poszÅ‚o Åºle** + **dlaczego** + **jak naprawiÄ‡** + **link do dokumentacji**.

### Zastosowanie w `/weekly-report`

Sara wdraÅ¼a te same zasady:

```markdown
## Enhanced Error Messages

When file not found:
1. Show what went wrong: "File not found: sprint-data.csv"
2. Suggest similar files (fuzzy match):
   - sprint_data.csv (1 char difference)
   - sprint-metrics.csv (similar pattern)
3. Provide actionable fix: "Check filename or run: ls *.csv"
4. Link to help: "See naming conventions: /help weekly-report"
```

**Twoja komenda powinna:**
- SugerowaÄ‡ alternatywy przy bÅ‚Ä™dach (podobne pliki, poprawiona skÅ‚adnia)
- DawaÄ‡ kontekst (nie tylko "bÅ‚Ä…d", ale "dlaczego" i "jak naprawiÄ‡")
- LinkowaÄ‡ do pomocy gdy bÅ‚Ä…d jest zÅ‚oÅ¼ony
- UÅ¼ywaÄ‡ fuzzy matching dla nazw plikÃ³w/argumentÃ³w

**Efekt:** UÅ¼ytkownik naprawia problem w 30 sekund zamiast 5 minut szukania w dokumentacji.

---

## CzÄ™Å›Ä‡ 3: Performance Problem - duÅ¼e pliki spowalniajÄ…

Trzy miesiÄ…ce pÃ³Åºniej team roÅ›nie. Z 5 osÃ³b do 15. Dane rosnÄ…:

Przed: `sprint-data.csv` = 200 rzÄ™dÃ³w, 50KB
Teraz: `sprint-data.csv` = 5000 rzÄ™dÃ³w, 500KB

Problem: `/weekly-report` zajmuje teraz 3 minuty zamiast 10 sekund.

Sara czeka, Claude "myÅ›li"... Okazuje siÄ™: Claude Å‚aduje caÅ‚y plik do swojej pamiÄ™ci roboczej zwanej kontekstem (context) - ograniczona przestrzeÅ„, w ktÃ³rej model przechowuje i przetwarza informacje. 500KB tekstu to okoÅ‚o 120 tysiÄ™cy tokenÃ³w - maÅ‚ych jednostek tekstu, ktÃ³re model analizuje. To spowalnia wszystko.

### RozwiÄ…zanie: Optymalizacja narzÄ™dzi - strategia dzielenia na fragmenty

Sara przepisaÅ‚a czÄ™Å›Ä‡ przetwarzania z uwzglÄ™dnieniem rozmiaru pliku:
```markdown
## Step 1.5: Size Detection and Strategy Selection

1. Check file size using Bash:
   ```
   ls -lh $ARGUMENTS
   ```

2. Based on size, select strategy:

   Strategy A: Small file (<1MB)
   - Read entire file at once
   - Process normally
   - Fast and simple

   Strategy B: Medium file (1-10MB)
   - Read in chunks (offset/limit)
   - Process in chunks of 1000 rows
   - Show progress: "Processing chunk 1/5..."
   - Combine results at the end

   Strategy C: Large file (>10MB)
   - Read first 100 lines (sample)
   - Read last 1000 lines (latest data)
   - Calculate metrics on sample
   - Mark in report: "Based on sample (first 100 + last 1000 rows)"

3. Inform user about selected strategy:
   - "File size: 500KB - using chunking strategy"
```

Dzielenie na fragmenty (chunking) dla Å›rednich plikÃ³w:
```markdown
## Step 2: Data Processing (medium files - chunked)

1. Count total rows:
   ```bash
   wc -l $ARGUMENTS
   ```

2. Calculate chunks:
   - Total rows: N
   - Chunk size: 1000
   - Number of chunks: N / 1000 rounded up

3. Process each chunk:

   FOR EACH chunk (FOR chunk_num IN 1 to num_chunks):
     a. Read chunk using offset/limit:
        - offset = (chunk_num - 1) * 1000
        - limit = 1000

     b. Extract metrics from chunk:
        - Tasks completed
        - Tasks in progress
        - Blockers

     c. Collect chunk results

     d. Show progress:
        "Processing chunk 3/5... (60% complete)"

4. Combine all chunks:
   - Sum completed tasks
   - Merge all blockers
   - Calculate averages

5. Generate final report
```

PiÄ…tek, 14:55. Sara uruchamia:
```
/weekly-report sprint-data.csv
```

Claude odpowiada:
```
File size: 500KB - using chunking strategy

Processing chunk 1/5... (20% complete)
Processing chunk 2/5... (40% complete)
Processing chunk 3/5... (60% complete)
Processing chunk 4/5... (80% complete)
Processing chunk 5/5... (100% complete)

Combining results...

Report saved: weekly-report-2026-02-02.md
Total time: 45 seconds
```

Wyniki:
- Czas przetwarzania: 3 minuty â†’ 45 sekund (4x szybciej)
- ZuÅ¼ycie tokenÃ³w (pamiÄ™ci roboczej): 120 tysiÄ™cy â†’ ~15 tysiÄ™cy (8x mniej)
- DoÅ›wiadczenie uÅ¼ytkownika: Widzi postÄ™p, wie co siÄ™ dzieje

Podobne wzorce dla przeszukiwania kodu przy uÅ¼yciu narzÄ™dzia Grep (narzÄ™dzie do szukania tekstu w plikach):

```markdown
Search code for pattern: $ARGUMENTS

## Progressive refinement strategy:

1. First: counting mode
   - Grep with output_mode: count
   - See how many matches exist

2. Decision based on count:
   - If <50: output_mode: content (show all)
   - If 50-200: output_mode: files_with_matches (list files only)
   - If >200: Refine search pattern (too many results!)

3. Always use head_limit to constrain results:
   - head_limit: 100 (maximum)

Saves tokens (memory), never overloads context.
```

### Badania pokazujÄ…: Optymalne rozmiary fragmentÃ³w

Badania **NVIDIA** (2024-2025) nad strategiami chunking dla AI weryfikujÄ… podejÅ›cie Sary:

**Kluczowe wyniki:**
- **Page-level chunking** osiÄ…ga najwyÅ¼szÄ… dokÅ‚adnoÅ›Ä‡ (0.648) z najmniejszÄ… wariancjÄ…
- **256-512 tokenÃ³w** optymalnie dla zapytaÅ„ wymagajÄ…cych konkretnych faktÃ³w
- **1024 tokeny** dla analiz wymagajÄ…cych szerszego kontekstu
- **Ekstrema (128 lub 2048 tokenÃ³w)** dajÄ… gorsze wyniki - za maÅ‚o lub za duÅ¼o kontekstu

**Dla przetwarzania plikÃ³w w chmurze (AWS S3 Best Practices):**
- **8-16MB** dla byte-range requests (optimum wydajnoÅ›ci)
- **10-100MB** dla operacji na duÅ¼ych dataset'ach
- **Tiered storage:** hot (SSD) dla nowych danych, cold (S3 Glacier) dla archiwum

**Zastosowanie w `/weekly-report` Sary:**
- Pliki **<1MB:** czytaj caÅ‚oÅ›Ä‡ (szybko, proste, ~250K tokenÃ³w)
- **1-10MB:** chunking po 1000 rzÄ™dÃ³w (~200-500KB/chunk, ~50-125K tokenÃ³w)
- **>10MB:** sampling (pierwsze 100 + ostatnie 1000 rzÄ™dÃ³w dla trendÃ³w)

**Kluczowa zasada:** Chunk size zaleÅ¼y od typu operacji:
- Analiza szczegÃ³Å‚owa â†’ mniejsze chunki (wiÄ™ksza precyzja)
- Trend analysis â†’ wiÄ™ksze chunki (wiÄ™cej kontekstu)
- Search operations â†’ adaptive (count â†’ decide â†’ constrain)

Å¹rÃ³dÅ‚a: [NVIDIA Research](https://developer.nvidia.com/blog/finding-the-best-chunking-strategy-for-accurate-ai-responses/), [Weaviate Guide](https://weaviate.io/blog/chunking-strategies-for-rag)

---

## CzÄ™Å›Ä‡ 4: Wieloetapowy proces - rÃ³wnolegle zamiast po kolei

Sara chce rozbudowaÄ‡ raport. Nie tylko tekst, ale teÅ¼:
1. Wykresy (velocity trend, task distribution)
2. Export do PDF

Obecny przepÅ‚yw pracy (po kolei):
```
1. PrzetwÃ³rz CSV (45s)
2. Wygeneruj wykresy (60s)
3. UtwÃ³rz PDF (30s)
Razem: 2min 15s
```

Wszystko po kolei. Claude czeka na zakoÅ„czenie kaÅ¼dego kroku.

### RozwiÄ…zanie: Zadania rÃ³wnolegÅ‚e + logika warunkowa

Sara przepisaÅ‚a komendÄ™ z fazami:
```markdown
## Phase 1: Validation and Preparation (sequential)
[Previous validation unchanged]

## Phase 2: Data Processing (sequential)
[Chunking strategy unchanged]

## Phase 3: Output Generation (parallel)

Now run these tasks SIMULTANEOUSLY (DO NOT wait for each to complete):

Task A: Generate Markdown Report
1. Create summary section
2. Add metrics tables
3. Add insights
4. Save: weekly-report-[date].md

Task B: Generate Charts
Run in parallel with Task A:
1. Create velocity chart
2. Create task distribution chart
3. Save charts: charts/velocity.png, charts/distribution.png

Task C: Prepare Stakeholder Data
Run in parallel with A and B:
1. Filter top 10 completed tasks
2. Extract blocker list
3. Save: stakeholders-summary.md

Wait for ALL tasks (A, B, C) to complete.

## Phase 4: Finalization (sequential)

After all parallel tasks complete:
1. Combine markdown report + charts
2. If user wants PDF:
   - Ask: "Generate PDF? (y/n)"
   - If yes: Use pandoc or similar tool
3. Final summary:
   - Report: weekly-report-2026-02-02.md
   - Charts: 2 files in charts/
   - Stakeholder summary: stakeholders-summary.md
   - PDF: weekly-report-2026-02-02.pdf (if requested)
```

Logika warunkowa (reagowanie na rÃ³Å¼ne sytuacje):
```markdown
## Phase 4: Finalization

1. Combine report + charts

2. Ask user: "Generate PDF version? (y/n)"

   IF user responds "y":
     a. Check if pandoc is available:
        ```bash
        which pandoc
        ```
     b. If NOT found:
        - Show: "pandoc is not installed"
        - Show: "Install: brew install pandoc (macOS)"
        - Skip PDF generation
     c. If found:
        - Generate PDF
        - Show: "PDF saved: weekly-report.pdf"

   IF user responds "n":
     - Skip PDF
     - Show: "Skipping PDF generation"
```

PiÄ…tek, 14:55. Sara uruchamia:
```
/weekly-report sprint-data.csv
```

Claude odpowiada:
```
File size: 500KB - using chunking strategy
[Processing chunks... 45s]

Generating outputs (parallel):
- Markdown report... âœ“ (30s)
- Charts (velocity + distribution)... âœ“ (60s)
- Stakeholder summary... âœ“ (25s)

All outputs ready in 60 seconds (limited by longest task)

Generate PDF version? (y/n)
```

Sara: `y`

```
PDF generated: weekly-report-2026-02-02.pdf

Summary:
âœ“ Report: weekly-report-2026-02-02.md
âœ“ Charts: charts/velocity.png, charts/distribution.png
âœ“ Stakeholder summary: stakeholders-summary.md
âœ“ PDF: weekly-report-2026-02-02.pdf

Total time: 2 minutes
```

Wyniki:
- Po kolei: 2min 15s
- RÃ³wnolegle: 2min (uwzglÄ™dniajÄ…c najdÅ‚uÅ¼sze zadanie = 60s wykresy + 45s przetwarzanie + 30s PDF)
- PrzyÅ›pieszenie: ~15% (w tym przypadku; dla bardziej zrÃ³wnowaÅ¼onych zadaÅ„ moÅ¼e byÄ‡ 2-3x)

Inne wzorce:

```markdown
## Example 1: Conditional branching (switch-case)

Deploy to environment: $ARGUMENTS

Based on $ARGUMENTS value, select appropriate path:

CASE "dev":
  - Skip tests (fast iteration)
  - Deploy immediately
  - No approval needed

CASE "staging":
  - Run basic tests
  - Deploy if tests pass
  - Notify QA team

CASE "prod":
  - Full test suite (MUST PASS)
  - Ask for approval
  - Create release tag
  - Prepare rollback plan

DEFAULT (when no value matches):
  Error: Unknown environment
  Allowed: dev, staging, prod
```

```markdown
## Example 2: Loops with progress tracking

Process multiple files: $ARGUMENTS (comma-separated)

1. Split $ARGUMENTS by comma â†’ array

2. FOR EACH file IN array:
   a. Check if file exists
   b. IF exists:
      - Process file
      - Collect result
   c. IF NOT exists:
      - Log warning
      - Continue to next
   d. Show progress: "Processed 3/7 files"

3. Summary:
   - Total: 7
   - Success: 6
   - Errors: 1
```

---

## CzÄ™Å›Ä‡ 5: Production Ready - ostatnie szlify

Sara uÅ¼ywa `/weekly-report` od 6 miesiÄ™cy. Team (teraz 20 osÃ³b) teÅ¼. Komenda dziaÅ‚a Å›wietnie.

Ale Sara chce dodaÄ‡ ostatnie elementy:
1. Logging - Å›ledzenie uÅ¼ycia (kto, kiedy, jaki plik)
2. Idempotency - safe do uruchomienia wielokrotnie
3. Better UX - helpful progress indicators

### Production Checklist

Sara dodaÅ‚a ostatnie elementy:

```markdown
## Production Features

1. Logging (Audit Trail)

After successful completion:
1. Log to file: .claude/logs/weekly-report.log
2. Format: [timestamp] [session_id] [user] [filename] [duration] [status]
3. Example:
   2026-02-02T14:55:30 abc123 sara sprint-data.csv 2m15s SUCCESS

Tip (v2.1.9+): UÅ¼yj `${CLAUDE_SESSION_ID}` w nazwie pliku logu dla korelacji sesji.

2. Idempotency Check

Before starting Phase 2:
1. Check if report already exists:
   - weekly-report-[today].md
2. If exists:
   - Ask: "Report for today already exists. Regenerate? (y/n)"
   - If no: STOP (safe, won't overwrite)
   - If yes: Continue (explicit consent)

3. Progress Indicators

During long operations:
- Show current step: "Step 2/4: Processing data..."
- Show estimated time: "(est. 45s remaining)"
- Show what's happening: "Reading chunk 3/5..."

4. Error Recovery

If ANY step fails:
1. Don't leave partial files
2. Show clear error with context
3. Suggest recovery action
4. Log error for debugging
```

Kompletna komenda produkcyjna:

```markdown
---
description: Production weekly report - comprehensive, validated, logged
argument-hint: [filename.csv]
model: sonnet
allowed-tools:
  - Read                           # Can read any files
  - Bash(ls *)                     # Can execute ls command with any parameters
  - Bash(wc *)                     # Can count lines in files
  - Write(weekly-report-*.md)      # Can write files weekly-report-[anything].md
  - Write(.claude/logs/*)          # Can write logs in .claude/logs/ directory
---

# /weekly-report - Production Version
# Purpose: Generate comprehensive weekly report from CSV data
# Usage: /weekly-report <filename.csv>
# Owner: Sara (PM team)
# Version: 5.0
# Last updated: 2026-02-02

Generate weekly report from CSV: $ARGUMENTS

## Phase 1: Validation and Preparation

1. Check if $ARGUMENTS provided:
   - If empty: Show help + examples, STOP

2. Check file extension:
   - If NOT .csv: Show error + suggestions, STOP

3. Check file exists:
   - If NOT found: Suggest similar files, STOP

4. Validate CSV structure:
   - Check required columns
   - If missing: Show what's needed, STOP

5. Idempotency check:
   - If report for today exists:
     * Ask: "Regenerate? (y/n)"
     * If no: STOP

## Phase 2: Size Detection & Data Processing

1. Check file size (ls -lh)

2. Choose strategy:
   - <1MB: Read at once
   - 1-10MB: Chunking
   - >10MB: Sampling

3. Process data:
   - Show progress for each chunk
   - Collect metrics
   - Handle errors gracefully

## Phase 3: Outputs (Parallel)

Run SIMULTANEOUSLY:

Task A: Markdown Report
- Summary, metrics, insights
- Save: weekly-report-[date].md

Task B: Charts
- Velocity trend
- Task distribution
- Save: charts/*.png

Task C: Stakeholder Summary
- Top 10 tasks
- Blockers
- Save: stakeholders-summary.md

Wait for all tasks.

## Phase 4: Finalization

1. Combine outputs

2. Ask: "Generate PDF? (y/n)"
   - If yes + pandoc available: Create PDF
   - If yes + no pandoc: Show install instructions
   - If no: Skip

3. Logging:
   - Write to .claude/logs/weekly-report.log
   - Format: [timestamp] [session_id] [user] [file] [duration] [status]
   - Optional: Use ${CLAUDE_SESSION_ID} for session correlation

4. Final summary:
   - List all generated files
   - Show total time
   - Success message

## Error Handling

If ANY error occurs:
- Don't leave partial files
- Log error details
- Show helpful message
- Suggest fix
```

---

## CzÄ™Å›Ä‡ 6: Zadanie i Podsumowanie

### Zadanie: Rozbuduj swojÄ… komendÄ™ z lekcji 11

Challenge: WeÅº jednÄ… z komend, ktÃ³re stworzyÅ‚eÅ› w lekcji 11, i dodaj:

1. Error handling:
   - Validation argumentÃ³w
   - Try-catch dla operacji
   - Helpful error messages

2. Performance optimization:
   - Size detection (dla plikÃ³w)
   - Chunking strategy lub sampling
   - Progress indicators

Requirements:
- Minimum 2 poziomy walidacji
- Minimum 1 optimization
- Clear error messages z suggested fixes

PrzykÅ‚ad:

JeÅ›li miaÅ‚eÅ› `/analyze-csv data.csv`, rozbuduj o:
- WalidacjÄ™: plik istnieje? to CSV? ma wymagane kolumny?
- WydajnoÅ›Ä‡: dzielenie na fragmenty dla plikÃ³w >1MB
- DoÅ›wiadczenie uÅ¼ytkownika: "Przetwarzanie fragmentu 2/5 (40% ukoÅ„czone)"

Dostarcz:
- PeÅ‚nÄ… komendÄ™ (rÃ³Å¼nica przed/po)
- Test z rÃ³Å¼nymi scenariuszami (scenariusz bez bÅ‚Ä™dÃ³w + scenariusze bÅ‚Ä™dÃ³w)
- Wyniki: ile czasu oszczÄ™dzasz? jak poprawiÅ‚o siÄ™ doÅ›wiadczenie uÅ¼ytkownika?

---

## Inne przykÅ‚ady produkcyjnych komend

Advanced patterns z tej lekcji dziaÅ‚ajÄ… dla kaÅ¼dego biaÅ‚ego koÅ‚nierzyka. Oto jak marketerzy i HR stosujÄ… te same techniki:

### Marketing: Campaign Performance Analyzer

**Problem:** Ania (marketing manager) analizuje 5 kampanii reklamowych co tydzieÅ„. Pobiera dane z Google Ads, Facebook Ads, LinkedIn - rÄ™cznie Å‚Ä…czy w Excel, tworzy pivot tables, wysyÅ‚a raport. 2 godziny kaÅ¼dego poniedziaÅ‚ku.

**Komenda:** `/analyze-campaigns campaign-data.json`

**Advanced patterns zastosowane:**

```markdown
---
model: haiku
allowed-tools:
  - Read(*.json)
  - Bash(jq *)
  - Write(reports/*.md)
---

## Phase 1: Validation Cascade

1. Check if $ARGUMENTS provided
   - If empty: Show usage + examples of JSON structure

2. Validate JSON format
   - Use: jq . $ARGUMENTS
   - If invalid: Show parsing error + fix suggestions

3. Check required fields
   - Required: campaign_name, platform, spend, conversions, CTR
   - If missing: List what's needed + example

4. Cross-field validation
   - IF spend > 0 AND conversions = 0:
     * Warning: "Campaign {name}: $5,000 spent, 0 conversions"
     * Flag for review
   - IF CTR < 0.5%:
     * Warning: "Low CTR on {platform}: {CTR}% (industry avg: 2-3%)"

## Phase 2: Size-Based Strategy

1. Count campaigns: jq '. | length' $ARGUMENTS

2. Strategy selection:
   - <10 campaigns: Full analysis
   - 10-50: Batch processing (chunks of 10)
   - >50: Top/bottom performers only (sampling)

## Phase 3: Parallel Analysis

Run SIMULTANEOUSLY:

Task A: Calculate ROI metrics
- Cost per conversion
- ROAS (Return on Ad Spend)
- Best/worst performers

Task B: Generate trend charts
- Spend over time
- CTR trends
- Platform comparison

Task C: Create recommendations
- Budget reallocation suggestions
- Underperforming campaigns to pause
- Top performers to scale

## Phase 4: Error Recovery

IF API data missing for platform:
- Use cached data from previous week
- Mark in report: "[Facebook] Using cached data (API unavailable)"
- Continue with other platforms
```

**Wyniki:**
- 2 godziny â†’ 15 minut (8x szybciej)
- Zero bÅ‚Ä™dÃ³w w obliczeniach (wczeÅ›niej: 2-3 literÃ³wki/tydzieÅ„)
- Rekomendacje automatyczne (wczeÅ›niej: manual guesswork)

---

### HR: Interview Feedback Compiler

**Problem:** Bartek (HR manager) kompiluje feedback z 5-8 rozmÃ³w rekrutacyjnych tygodniowo. KaÅ¼da rozmowa = 3-4 interviewerÃ³w = 15-30 notatek do przejrzenia, zsumowania, wyciÄ…gniÄ™cia konsensusu. 3 godziny kaÅ¼dego piÄ…tku.

**Komenda:** `/compile-feedback candidate-name`

**Advanced patterns zastosowane:**

```markdown
---
model: sonnet
allowed-tools:
  - Glob(interviews/**/*.md)
  - Read
  - Write(feedback-reports/*.md)
---

## Phase 1: Smart Discovery + Validation

1. Find feedback files for candidate
   - Pattern: interviews/**/{candidate-name}*.md
   - Use Glob with fuzzy matching

2. Validate found files:
   - If 0 files: "No feedback found for {name}"
     * Suggest similar names: Did you mean: "Jan Kowalski" or "Jana Kowal"?
   - If <3 files: Warning: "Only {count} feedback files (expected 3-4)"
     * Ask: "Continue with partial data? (y/n)"

3. Check file structure:
   - Required sections: Technical Skills, Cultural Fit, Red Flags, Recommendation
   - If missing: Log warning, continue with available sections

## Phase 2: Idempotency Check

Before processing:
1. Check if report exists: feedback-reports/{candidate-name}-compiled.md
2. If exists + created today:
   - Ask: "Report for {name} already exists (created {time}). Regenerate? (y/n)"
   - If no: STOP (safe, won't overwrite)

## Phase 3: Parallel Aggregation

Run SIMULTANEOUSLY:

Task A: Score aggregation
- Average technical score (1-5 scale)
- Cultural fit consensus
- Identify outliers (one person rated 5, others 2)

Task B: Extract key quotes
- Top 3 positive comments
- All red flags (critical)
- Unique insights

Task C: Generate recommendation
- Hire/No-hire consensus
- Concerns to address
- Next steps

## Phase 4: Graceful Degradation

IF interviewer feedback incomplete:
- Mark: "[Interviewer: Jane] - Partial feedback (missing Cultural Fit)"
- Continue with available data
- Final report shows: "Based on 4/5 complete feedbacks"

IF conflicting recommendations (2 hire, 2 no-hire):
- Highlight conflict prominently
- Show reasoning from both sides
- Suggest: "Schedule discussion meeting"
```

**Wyniki:**
- 3 godziny â†’ 20 minut (9x szybciej)
- Zero pominiÄ™tych red flags (wczeÅ›niej: 1-2/miesiÄ…c przez manual oversight)
- SpÃ³jny format raportÃ³w (wczeÅ›niej: kaÅ¼dy raport inny)
- Archiwum z logami: `.claude/logs/feedback-compiler.log` dla compliance

**Metryki po 3 miesiÄ…cach:**
- 156 raportÃ³w wygenerowanych
- 468 godzin oszczÄ™dnoÅ›ci (156 Ã— 3h)
- 95% accuracy (5% wymaga rÄ™cznych poprawek przy edge cases)

---

## SÅ‚owniczek

**Frontmatter (nagÅ‚Ã³wki)** - Opcjonalna sekcja na poczÄ…tku pliku `.md` (miÄ™dzy `---`), definiuje parametry komendy. Podstawowe pola dla custom commands: description (opis w `/help`), argument-hint (wskazÃ³wka w autocomplete), model (haiku/sonnet/opus), allowed-tools (uprawnienia), disable-model-invocation (blokada auto-wywoÅ‚ania). Zaawansowane opcje dostÄ™pne tylko dla Skills (`.claude/skills/*/SKILL.md`, nie dla `.claude/commands/*.md`): context: fork (uruchamia skill w izolowanym subagent context), agent: [typ] (wybiera typ subagenta), hooks: (lifecycle hooks). SzczegÃ³Å‚y Skills w module 9. Zobacz lekcjÄ™ 11 dla szczegÃ³Å‚Ã³w podstawowych pÃ³l.

**Multi-step workflow (wieloetapowy przepÅ‚yw pracy)** - Komenda skÅ‚adajÄ…ca siÄ™ z wielu krokÃ³w wykonywanych po kolei (sekwencyjnie) lub rÃ³wnoczeÅ›nie (rÃ³wnolegle), czÄ™sto z walidacjÄ… miÄ™dzy fazami.

**Error handling (obsÅ‚uga bÅ‚Ä™dÃ³w)** - Wzorzec try-catch (sprÃ³buj-przechwyÄ‡) w komendzie - sprawdzanie czy operacja siÄ™ powiodÅ‚a i obsÅ‚uga bÅ‚Ä™dÃ³w z czytelnym komunikatem oraz sugerowanym rozwiÄ…zaniem.

**Validation cascade (kaskadowa walidacja)** - Wielopoziomowe sprawdzanie poprawnoÅ›ci (argumenty â†’ plik â†’ struktura â†’ dane). KaÅ¼dy poziom dodaje pewnoÅ›Ä‡, wczesne wyjÅ›cia przy bÅ‚Ä™dzie oszczÄ™dzajÄ… czas.

**Chunking (dzielenie na fragmenty)** - Przetwarzanie duÅ¼ych plikÃ³w/danych w kawaÅ‚kach zamiast wszystkiego na raz (all-at-once). OszczÄ™dza pamiÄ™Ä‡ (memory) i tokeny.

**Idempotency (idempotentnoÅ›Ä‡)** - WÅ‚aÅ›ciwoÅ›Ä‡ komendy, ktÃ³rÄ… moÅ¼na uruchomiÄ‡ wiele razy bez efektÃ³w ubocznych (side effects). Sprawdza co juÅ¼ istnieje, tworzy tylko brakujÄ…ce elementy, nie nadpisuje bez potwierdzenia.

**Progressive refinement (stopniowe doprecyzowywanie)** - Strategia dla wyszukiwania (Grep): najpierw policz wyniki (count), potem na podstawie liczby zdecyduj czy pokazaÄ‡ caÅ‚Ä… zawartoÅ›Ä‡ (content) czy tylko nazwy plikÃ³w (files). OszczÄ™dza tokeny.

**Graceful degradation (Å‚agodna degradacja)** - Strategie awaryjne (fallback) gdy gÅ‚Ã³wne podejÅ›cie zawiedzie: peÅ‚na analiza â†’ prÃ³bka â†’ podstawowa â†’ bÅ‚Ä…d. Zawsze dostarcz COKOLWIEK, nawet jeÅ›li nie jest to idealne rozwiÄ…zanie.

**Parallel execution (wykonywanie rÃ³wnolegÅ‚e)** - Uruchomienie wielu zadaÅ„ rÃ³wnoczeÅ›nie (nie po kolei/sekwencyjnie). CaÅ‚kowity czas = czas najdÅ‚uÅ¼szego zadania. PrzyÅ›pieszenie 2-3x.

**Audit trail (Å›lad audytu)** - Rejestrowanie (logging) wszystkich kluczowych operacji do pliku (znacznik czasu, uÅ¼ytkownik, komenda, wynik). Przydatne do debugowania (znajdowania bÅ‚Ä™dÃ³w), zgodnoÅ›ci z przepisami i analityki.

**Helpful error messages (pomocne komunikaty bÅ‚Ä™dÃ³w)** - Nie tylko "BÅ‚Ä…d", ale: co poszÅ‚o Åºle + dlaczego + jak naprawiÄ‡ + przykÅ‚ad. Konkretne (specific) i moÅ¼liwe do wykonania (actionable).

**Size-based strategy (strategia oparta na rozmiarze)** - WybÃ³r metody przetwarzania na podstawie rozmiaru danych: <1MB czytaj od razu (at once), 1-10MB dziel na fragmenty (chunking), >10MB prÃ³bkuj (sampling).

**Progress indicators (wskaÅºniki postÄ™pu)** - Pokazywanie postÄ™pu podczas dÅ‚ugich operacji ("Step 3/5", "60% complete", "estimated 30s remaining"). UÅ¼ytkownik wie co siÄ™ dzieje.

**Conditional logic (logika warunkowa)** - Instrukcje IF-THEN-ELSE (JEÅšLI-TO-W_PRZECIWNYM_RAZIE) w komendzie. Dostosowuje siÄ™ do sytuacji: plik duÅ¼y? â†’ dziel na fragmenty; maÅ‚y? â†’ czytaj od razu.

**Sequential vs Parallel (sekwencyjne vs rÃ³wnolegÅ‚e)** - Sekwencyjne: zadanie 1 â†’ zadanie 2 â†’ zadanie 3 (caÅ‚kowity czas = suma). RÃ³wnolegÅ‚e: wszystkie naraz (caÅ‚kowity czas = maksimum, czyli najdÅ‚uÅ¼sze zadanie).

**Shorthand arguments (v2.1.19+)** - Uproszczona skÅ‚adnia dostÄ™pu do argumentÃ³w: `$0`, `$1`, `$2` jako skrÃ³t od peÅ‚nej skÅ‚adni bracket `$ARGUMENTS[0]`, `$ARGUMENTS[1]`, `$ARGUMENTS[2]`. PrzykÅ‚ad: `/command arg1 arg2` â†’ `$0` = "arg1", `$1` = "arg2". Obie skÅ‚adnie dziaÅ‚ajÄ… identycznie, shorthand jest zwiÄ™zÅ‚y, bracket jawny. SzczegÃ³Å‚y w lekcji 11.

---

Å¹rÃ³dÅ‚a:
- [Best practices](https://code.claude.com/docs/en/best-practices)
- [Common workflows](https://code.claude.com/docs/en/common-workflows)
- [Production commands](https://github.com/wshobson/commands)
- [Real-world automation](https://www.eesel.ai/blog/claude-code-workflow-automation)
- [Builder.io best practices](https://www.builder.io/blog/claude-code)
- [Custom commands guide](https://www.aiengineering.report/p/claude-code-custom-commands-3-practical)
- [Boris Cherny workflow](https://medium.com/vibe-coding/claude-codes-creator-100-prs-a-week-his-setup-will-surprise-you-7d6939c99f2b)
